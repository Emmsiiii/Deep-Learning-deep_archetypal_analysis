# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HpHyh1KPyToCTu_SdPwvAKl7rxAS8Oyq
"""

!git clone https://github.com/sottorivalab/midaa.git
!pip install ./midaa

import numpy as np
import struct
import anndata
import scanpy as sc
import matplotlib.pyplot as plt
import seaborn as sns
import midaa
import kagglehub

# ========================
# 1) Download MNIST
# ========================
path = kagglehub.dataset_download("hojjatk/mnist-dataset") + "/"
print("Dataset path:", path)

# ========================
# 2) Load IDX format MNIST
# ========================
def load_idx_images(filename):
    with open(filename, "rb") as f:
        _, num, rows, cols = struct.unpack(">IIII", f.read(16))
        data = np.frombuffer(f.read(), dtype=np.uint8)
        return data.reshape(num, rows, cols)

def load_idx_labels(filename):
    with open(filename, "rb") as f:
        _, num = struct.unpack(">II", f.read(8))
        return np.frombuffer(f.read(), dtype=np.uint8)

X = load_idx_images(path + "train-images-idx3-ubyte/train-images-idx3-ubyte")
y = load_idx_labels(path + "train-labels-idx1-ubyte/train-labels-idx1-ubyte")

print("Full dataset:", X.shape, y.shape)

# ========================
# 3) Optional: Use subset to speed training
# ========================
n = 10000
X = X[:n]
y = y[:n]

# Flatten â†’ MIDAA expects genes/features in columns
X_flat = X.reshape(n, -1).astype(np.float32) / 255.0

# ========================
# 4) Create AnnData
# ========================
adata = anndata.AnnData(X_flat)
adata.obs["label"] = y.astype(str)
adata.obsm["images"] = X  # store images here for visualization later

print(adata)

# ========================
# 5) Prepare MIDAA input (Vector mode)
# ========================
input_matrix, normalization_factor, input_types = midaa.get_input_params_adata(adata)

# ========================
# 6) Fit MIDAA
# ========================
res = midaa.fit_MIDAA(
    input_matrix=input_matrix,
    normalization_factor=normalization_factor,
    input_types=input_types,
    narchetypes=5,
    steps=1500,
    batch_size=512,
    lr=0.003,
    CUDA=False
)

# ========================
# 7) Plot ELBO
# ========================
midaa.plot_ELBO(res)

# ========================
# 8) Simplex Plot
# ========================
midaa.plot_archetypes_simplex(
    res,
    color_by=adata.obs["label"],
    cmap="tab10"
)
plt.show()

# ========================
# 9) UMAP embeddings and per-archetype UMAP panels
# ========================
adata.obsm["X_aa"] = res["inferred_quantities"]["A"] @ res["inferred_quantities"]["archetypes_inferred"]

sc.pp.neighbors(adata, use_rep="X_aa")
sc.tl.umap(adata)
sc.pl.umap(adata, color="label", legend_loc="on data")

A = res["inferred_quantities"]["A"]
for k in range(A.shape[1]):
    adata.obs[f"arc{k+1}"] = A[:, k]

sc.pl.umap(adata, color=[f"arc{k+1}" for k in range(A.shape[1])], vmax="p95")

# ========================
# 10) Top images per archetype
# ========================
def show_top(k, top=25):
    idx = np.argsort(-A[:,k])[:top]
    imgs = adata.obsm["images"][idx]
    plt.figure(figsize=(6,6))
    m = int(np.sqrt(top))
    for i in range(top):
        plt.subplot(m,m,i+1)
        plt.imshow(imgs[i], cmap="gray")
        plt.axis("off")
    plt.suptitle(f"Top samples for archetype {k+1}")
    plt.show()

for k in range(A.shape[1]):
    show_top(k)